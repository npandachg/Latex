\chapter{Probability space}
We specialize the general measure theory to provide a description of a probability space.

\begin{Definition}[name=Probability space]
    A probability space  is a measure space $\measureS{X}{\algebra{M}}{\mu}$ with $\measure{X} = 1$. The
    measure $\mu$ is called a probability measure. The element of $\algebra{M}$ are called events.
    In classical notation, $X$ is denoted by $\Omega$ and is called the sample space, 
    $\algebra{M}$ is denoted by $\algebra{F}$ and
    $\mu$ by $\mathbb{P}$. Thus a probability space is denoted by $\probS$.
\end{Definition}
Note that if $E \in \algebra{F}$ then $\comp{E} \in \algebra{F}$. This means that
$\probMeasure{\comp{E}} = 1 - \probMeasure{E}$. This is a very useful result that is used very
frequently in probability.
\begin{Example}
    We consider a few probability spaces.
    \begin{enumerate}
	\item
	    Let $\Omega$ be countable set, $\Omega = \lbrace\omega_1,\omega_2,\dots\rbrace$. Suppose each
	    point $\omega_i$ has probability $p_i$ of occuring so that $\sum\limits_{i}p_i = 1$. Let
	    $\algebra{F} = \powSet{X}$. Define,
	    \[\probMeasure{A} = \sum\limits_{x_i\in A}p_i,\quad A\in\algebra{F}.\]
	    Then, $\probMeas$ is a probability measure. $\probS$ is called
	    the discrete probability space.
	\item
	    Let $\Omega = \interval{0}{1}$, $\algebra{F}$ be the lebesgue measurable sets in
	    $\interval{0}{1}$ and $\probMeas$ be the Lebesgue measure. This is called the uniform
	    distribution. 
	\item
	    Let $\Omega = \R$ and set $F(x) = \frac{1}{2} + \frac{1}{\pi}\arctan(x)$. The function
	    $F(x)$ is continuous, monotone increasing and non-negative with 
	    $\lim_{x\to-\infty}F(x) = 0$ and  $\lim_{x\to\infty}F(x) = 1$. The distribution function
	    $F$ defines a unique measure on $\borelS{\R}$. This is called the Cauchy distribution.
    \end{enumerate}
\end{Example}
Next, we describe a measure theoretic probability model.

\begin{Definition}[name=Measure theoretic probability model]
    Let $X$ be the space of a probabilistic process. A measure theoretic model of the
    process is an identification of $X$ with a set $\Omega$, a 
    $\sigmaAlgebra$ $\algebra{F}$ on $\Omega$ and a measure $\probMeas$ on $\algebra{F}$. 
    A subset $E\subset X$ is called a \emph{plausible} event if $\Omega_{E} \in \algebra{F}$, 
    where $\Omega_{E}$ is the set of 
    points in $\Omega$ which corresponds to points in $X$ for which $E$ occurs. 
    We denote the probability of $E$ by $P(E)$ and set it to $\probMeasure{\Omega_E}$.  
\end{Definition}
The notation $\Omega_{E}$ here signifies that $X$ could be any probabilistic set up where we
want to assign probabilities to subsets $E$ of $X$. In order to build a measure theoretic framework we
identify with $X$ a set which we call the sample space $\Omega$ and construct a $\sigmaAlgebra$ on $\Omega$. 
Such an identification and construction is not unique. To
assign probabilities to events $E$ in $X$, we see if the corresponding set is in $\algebra{F}$. If it is, we
assign it a probability; if not, we deem the set $E$ as not plausible within our measure theoretic framework.


Now we will build a measure theoretic probability model to analyze an experiment that involves a
sequence of infinite coin tosses. Let us assume we have a fair coin and we toss it infinitely many
times. Also it will be safe to assume that any outcome of a toss doesn't depend on what preceeded it
and will not affect any future outcomes. 
Ofcourse, such an experiment is just a thought experiment and cannot be practically carried
out. Our sample space will consist of \emph{points} like $(H,T,H,H,H,T,H,T,T,H,H,\dots,)$. We may
have events such as the event $E$ of all those infinite sequences such that the first toss is a $H$.
How do we assign a probability to such an event. First a couple of definitions.
\begin{Definition}[name=Bernoulli trial and sequences.]
    Suppose an experiment has two possible outcomes. A finite number of repetitions of the
    experiment is a called a Bernoulli trial. An infinite sequence of experiments is called a
    Bernoulli sequence.
\end{Definition}
Let $\mathcal{B}$ be the set of all Bernoulli sequences. Thus $\mathcal{B}$ is the space of
our experiment of infinite coin tosses. In order to prescribe probability to events in a measure
theoretic framework we need to identify $\mathcal{B}$ with the sample space of a probabilistic
space. The following proposition says that there is a one to one correspondence between the unit
interval and $\mathcal{B}$.

\begin{Proposition}
    There exists a $1-1$ correspondence from $\hInt{0}{1}$ into $\mathcal{B}$.
\end{Proposition}
\begin{proof}
    Let $\omega \in \interval{0}{1}$. Then $\omega$ can be written as a binary expansion given by,
    \[\omega = \infiniteSum{\frac{a_i}{2^i}}{i},\quad a_i= 0\,\text{or}\,1.\]
    Let $\map{f}{\interval{0}{1}}{\mathcal{B}}$ be the map given by,
    \begin{equation*}
	f(\omega) = 
	\begin{cases}
	    H\,&\text{if $a_i = 1$},\\
	    T\,&\text{if $a_i = 0$}.
	\end{cases}
    \end{equation*}
    The map defined above fails to be a function since there are real numbers that have two
    different binary expansion. For example $\frac{1}{2} = 0.10\dots$ or 
    $\frac{1}{2} = 0.0111\dots$. To avoid this trouble we chose the later expansion. What this means
    is that the function fails to be onto since we discard binary expansions terminating in an
    infinite sequences of $0$ which corresponds to Bernoulli sequence ending in infinite $T$'s. Thus
    there is a $1-1$ correspondence from $\hInt{0}{1}$ into $\mathcal{B}$.
\end{proof}
\begin{Remark}
    Since $\hInt{0}{1}$ is uncountable, this implies that $\mathcal{B}$ is uncountable. However,
    because the map isn't bijective we cannot identify every bernoulli sequence with a real number
    in the unit interval. However there is only a countable subset of $\mathcal{B}$ that is not
    mapped by $f$ above and since we know that a measure of a countable set is $0$ we can neglect
    this set to build our measure theoretic framework. To show this, let $\mathcal{B}_{\text{neg}}$ be the
    Bernoulli sequence that are not mapped by $f$. These are the sequences that end in infnite
    $T$'s. Let $\mathcal{B}_{\text{neg}}^{k}$ be the bernoulli sequences that end in inifinite $T$'s
    after the $k^{th}$ toss. Then $\mathcal{B}_{\text{neg}}^{k}$ is countable. But 
    $\mathcal{B}_{\text{neg}} = \bigcup\limits_{k}\mathcal{B}_{\text{neg}}^{k}$ and so the set that
    is not mapped by $f$ is countable. 
\end{Remark}
We can make $\mathcal{B}$ into a probability space by using the Lebesgue measure on the unit
interval.
\begin{Definition}[name=Borel Principle]
    Let $\Omega = \hInt{0}{1}$. If $E$ is a \textbf{plausible} event of Bernoulli sequences, we
    denote by $\Omega_{E}$ as the subset of real numbers in $\hInt{0}{1}$ that are Lebesgue
    measurable and are given by the corresponding binary expansion. 
    We set the probability of $E$, denoted by $P(E)$, as $\measure{\Omega_{E}}$.  
\end{Definition}
\begin{Example}
    Let $E = $ event where $H$ occurs on the first toss.
    $E = \lbrace H, X_1, X_2, X_3,\dots \rbrace$. The corresponding set in $\Omega$ is 
    \[\Omega_{E} = \set{\omega\in\Omega; x=0.1d_1d_2d_3\dots}{d_i = 0\,\text{or}\,1}.\]
    Is $E$ plausibe? That is is $\Omega_{E}$ Lebesgue measurable? The smallest number in
    $\Omega_{E}$ is $0.100000\dots$ while the largest number is $0.11111\dots$. Thus
    $\Omega_E = \hInt{1/2}{1}$ which is certainly Lebesgue measurable. Thus $P(E) =
    \measure{\hInt{1/2}{1}} = 1/2$.
\end{Example}
\begin{Example}
    Let $E$ be the event where the first $N$ tosses are prescribed. For example we could have for
    $N=3$, $HTT$ as the first $3$ tosses. Thus,
    \[\Omega_{E} = \set{\omega\in\Omega; x=0.a_1a_2\dots a_{N}d_1d_2d_3\dots}{d_i =
	    0\,\text{or}\,1}.\]
    Is $\Omega_{E}$ Lebesgue measurable? Again the smallest number is $a_1a_2\dots a_N
    00000\dots$ while the largest number is $a_1a_2\dots a_N 11111$. Let $s = a_1a_2\dots
    a_N000\dots$. Then $a_1a_2\dots a_N 111\dots = s + \sum\limits_{i \geq N+1}^{\infty}1/2^{i} = s
    = 1/2^N$. Thus $\Omega_{E} = \hInt{s}{s+\frac{1}{2^N}}$ which is certainly Lebesgue
    measurable. Thus $P(E) = \measure{\hInt{s}{s+\frac{1}{2^N}}} = \frac{1}{2^N}$.
\end{Example}

\begin{Example}
    Consider the event $E$ in which $H$ occurs in the $N^{th}$ toss. The corresponding set 
    \[\Omega_{E} = \set{\omega\in\Omega; x=0.d_1d_2\dots 1 d_{N+1}d_{N+2}d_{N+3}\dots}{d_i =
	    0\,\text{or}\,1}\]
    Here $\Omega_{E}$ can be thought of as a union of disjoint interval. As a concrete case,
    consider $N=3$. Then we have the following cases:
    $HTH,HHH,THH,HTH$. These correspond to 4 disjoint intervals of length $1/2^3$. Thus $P(E) = 4/8
    =1/2$. In general, $P(E) = 2^{N-1}/2^N = 1/2$.
\end{Example}
In all these examples the Events have corresponded to either intervals or union of intervals.
However, the power of a measure theoretic framework is not apparent since the above examples can be
easily seen even in a discrete setting. To show the power of the Borel principle, we will look at
the Weak Law of Large Numbers. See Appendix for a connection between weak law of large numbers and
the approximation of continuous functions by polynomials.

We believe that we should be able to detect the probabilities of Heads and Tails when flipping a
coin by examining the results of many experiments. For example suppose the probability that Head
occurs in a coin toss is $p$. If we don't know what $p$ is we can carry the experiment a large
number of times and record the number of Heads that occured. The fraction of Heads then must give us
some indication of $p$. However, a precise statement of this intuition is difficult to formulate.

Say we are tossing a fair coin whose results are independent of any other coin tosses. 
If we let $H_n$ to be the number of heads that occur in the first $n$ tosses, we \textbf{might} like
to show
\[\lim\limits_{n\to\infty}\frac{H_n}{n} = \frac{1}{2}.\]
However this is certainly not true. In other words, we could get a sequence that ends in $H$
infinitely or in $T$ infinitely. Intuitively, such sequences are not likely or typical. What is
clear is that we need to create a careful formulation.

\begin{Definition}[name=Number of Heads]
    For $\omega \in \Omega$, define
    \[S_N(\omega) = a_1 + \cdots + a_N,\quad \omega = 0.a_1a_2\dots\]
    $S_N$ gives the number of heads in the first $N$ tosses of the Bernoulli sequence corresponding
    to $\omega$. So $H_N = S_N(\omega)$.
\end{Definition}
Now, consider the event $E$ that the fraction of heads $H$ tends to $1/2$. The corresponding set 

\begin{equation}\label{eq:SLLN_lebesgue_set}
    \Omega_{E} = \set{\omega\in\Omega}{\atob{\frac{S_n(\omega)}{n}}{\frac{1}{2}}\quad\atob{n}{\infty}}
\end{equation}
Is $\Omega_{E}$ Lebesgue measurable? This set is highly complicated. What can we say about its
elements? If $\omega \in \Omega_{E}$ then no matter what $\epsilon$ we take, there is an
integer $k$ such that for all integers $n$ greater than $k$, the fraction of heads is within an
$\epsilon$ of $\frac{1}{2}$. That is,
\[\forEv{\epsilon}\thereIs{k}\forEv{n}\suchThat{n\geq
	k}{\implies}{\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} < \epsilon}.\]
By the archimedes principle, for every $\epsilon > 0$, there is a positive integer $r$ such that
$\frac{1}{r} < \epsilon$. Thus the above condition can be written as,
\[\forEv{r}\thereIs{k}\forEv{n}\suchThat{n\geq
	k}{\implies}{\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} < \frac{1}{r}}.\]
The advantage of such a formulation is that now we have positive integers as quantifiers. Let,
\[A_{n,r} = \set{\omega\in\Omega}{\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} < \frac{1}{r}}.\]
This means that,
\[\frac{n}{2}(\frac{1}{2} - \frac{1}{r}) < a_1 + a_2 + \cdots + a_n < 
    \frac{n}{2}(\frac{1}{2} + \frac{1}{r}).\]
Since $a_i$ are either $0$ or $1$ we have a finite choice of these. Thus $A_{n,r}$ is a disjoint
union of intervals in $\Omega$ and is Lebesgue measurable. This means that,
\[\Omega_{E} = \bigcap\limits_{r = 1}^{\infty}\bigcup\limits_{k = 1}^{\infty}\bigcap\limits_{n\geq
    k}^{\infty}A_{n,r},\]
is Lebesgue measurable since it is just a countable union and intersection of a Lebesgue measurable
set. This is easy to see: if $\omega \in \Omega_{E}$ then for every $r$, 
$\omega \in \bigcup\limits_{k = 1}^{\infty}\bigcap\limits_{n\geq k}^{\infty}A_{n,r}$. This means that
there is a $k$ such that $\omega \in \bigcap\limits_{n\geq k}^{\infty}A_{n,r}$. Thus for all $n \geq
k$, $\omega \in A_{n,r}$, i.e $\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} < \frac{1}{r}$.
Thus $\Omega_{E}$ is Lebesgue measurable in $\Omega$. 

What is $P(E)$ i.e.~what is $\measure{\Omega_{E}}$? Intiuitely, we would guess that $P(E) = 1$.
Indeed that is the case and the result is the famous \textbf{Strong Law of Large numbers}. To prove
this statement we will show $\measure{\comp{\Omega_{E}}} = 0$. There are two ways to show a set
has zero Lebesgue measure. Either the set is countable or it can be covered by intervals whose
countable sum of measures can be made arbitrarily small. See~\ref{prop:lebesgue_meas_0}. We can rule
out the first option which seems surprising at first but follows from a simple observation. 
Consider the map, $\map{\sigma}{\Omega}{\Omega}$ given by,
\[\sigma(\omega) = a_{1}11a_{2}11a_{3}11\cdots,\quad \omega = a_1a_2a_3\cdots.\]
Since $\sigma$ is injective, $\sigma(\Omega) \subset \Omega$ is uncountable. Fix an $\omega \in
\Omega$. Let $N = 3n$ for any positive integer $n$. Let $y \in \Omega$ be give by $\sigma(\omega)$.
Then $S_N(y)$ is the number of heads in the first $N$ tosses which is always greater than $2n$, thus
\[\frac{S_N(y)}{N} \geq \frac{2}{3}.\]
This means that $\sigma(\Omega) \subset \indxComp{\algebra{F}}{E}$ and hence
$\indxComp{\algebra{F}}{E}$ is uncountable.


But first we will show a \emph{weaker} 
statement. The notions weaker and stronger will be explained later when we describe measurable
functions. Given an $\epsilon > 0$ let 
\begin{equation}\label{eq:WLLN_lebesgue_set}
    \Omega_{E_N} =
\set{\omega\in\Omega}{\distR{\frac{S_n(\omega)}{N}}{\frac{1}{2}} \leq \epsilon}.
\end{equation} 
Note that,
$\Omega_{E_N}$ is Lebesgue measurable because we can re-formulate the definition by using
$\frac{1}{r}$, where $r$ is a positive integer such that $\frac{1}{r} < \epsilon$. 

We gather these two notions in the following theorem.
\begin{Theorem}[name=Law of large numbers for Bernoulli sequences]\label{thm:LLN_bernoulli_seq}
    Let $\Omega = \hInt{0}{1}$ be the sample space identified with the Bernoulli sequences. Let
    $\algebra{F}$ be the Lebesgue measurable sets in $\Omega$ and $\mu$ be the corresponding
    Lebesgue measure. Thus, $\measureS{\Omega}{\algebra{F}}{\mu}$ is a probability space. Let
    $\Omega_{E}$ be the set in $\algebra{F}$ as in~\ref{eq:SLLN_lebesgue_set} and
    $\Omega_{E_N}$ be the set in $\algebra{F}$ as in~\ref{eq:WLLN_lebesgue_set}. Then, 
    \begin{enumerate}
	\item
	    For every $\epsilon > 0$, 
	    \[\lim\limits_{N\to\infty}
		\measure{\set{\omega\in\Omega}{\distR{\frac{S_n(\omega)}{N}}{\frac{1}{2}} \leq \epsilon}} = 1\]
	    i.e.,
	    \[\atob{P({E_N})}{1}\,\text{as}\,\atob{N}{\infty}\]
	\item
	    \[\measure{\set{\omega\in\Omega}{\lim\limits_{N\to\infty}\frac{S_N(\omega)}{N}= \frac{1}{2}}}
	    = 1\]
	    i.e.,
	    \[P({E}) = 1.\]
    \end{enumerate}
\end{Theorem}
We will need a few more definitions and results from Riemann integration to prove this. The standard
approach will be to prove results about the complement of the set.

Each digit of the binary expansion of a real number in $\Omega$ (where we choose a unique binary
expansion) can be thought as a selection of a dyadic partition of $\Omega$ as in~\ref{def:dyadic_cube}.
At level $1$ we bisect the interval $\hInt{0}{1}$. The binary digit when in left is $0$ and $1$
when in right. At level $2$, we bisect each of these to get four intervals indexed as $00,01,10,12$.
Continuing, we achieve a dyadic partition of $\hInt{0}{1}$ at each level which corresponds to a
digit in the binary expansion. Since each digit corresponds to a Bernoulli trial, we get a
correspondence of the partition with the Bernoulli sequence. 

Each Level $k$ partitions $\Omega$  into $2^{k}$ 
intervals of $\interval[open left]{\frac{l}{2^{k}}}{\frac{l+1}{2^{k}}}$ 
for $0 \leq l < 2^{k}$.  
At each level of the partition we
define the Rademacher functions which take the value of $1$ when the binary digit is $1$ and
$-1$ when the binary digit is $0$. Thus $R_1$ has two values, $R_2$ has $4$ values, $R_n$ has $2^n$
values. This is made precise in the definition below. See~\ref{fig:tikz:rademacher}.

\begin{figure}
  \includestandalone[width=0.5\textwidth]{tex/tikz_figures/rademacher_1}
  \caption{We show the first three levels of dyadic partition with the corresponding Rademacher
      functions $R_1$, $R_2$ and $R_3$. Red shows that Rademacher functions takes a value $-1$,
      while blue shows that the function takes a value $1$.}\label{fig:tikz:rademacher}
\end{figure}

\begin{Definition}[name=Rademacher function]
    For $\omega \in \Omega$, we define the $k^{th}$ Rademacher function by,
    \begin{equation*}
	R_k(\omega) = 2a_k -1,\quad \omega = 0.a_1a_2\dots
    \end{equation*}
    This means that,
    \begin{equation*}
	R_k(\omega) = 
	\begin{cases}
	    1,\,&a_k = 1,\\
	    -1,\,&a_k = 0
	\end{cases}
    \end{equation*}
\end{Definition}
We can interpret $R_k$ like this. Suppose we bet on a sequence of coin tosses such that at each toss,
we win $\$1$ if it is heads and lose $\$1$ if it is tails. Then $R_k(\omega)$ is the amount won or
lost at the $k^{th}$ toss in the sequence of tosses represented by $\omega$.
\begin{Proposition}\label{prop:rademacher}
    Let $R_k$ denote the $k^{th}$ Rademacher function.
    \begin{enumerate}
	\item
	    $ \int\limits_{0}^{1}R_{k_1}(x)R_{k_2}(x)\dots R_{k_n}(x) = 0\,\text{or}\,1$
	    for any sequence $k_1 \leq k_2 \leq \cdots \leq k_n$. 
	\item
	   For $x \in \interval[open left]{0}{1}$, 
	    \[ \sumInf{R_i(x)2^{-i}} = 2x - 1. \]
    \end{enumerate}
\end{Proposition}
\begin{proof}
    We prove in order.
    \begin{enumerate}
	\item
	   Each $R_{k_i}$ is defined on partitions of $\interval[open left]{0}{1}$ into $2^{k_i}$ 
	   intervals of $\interval[open left]{\frac{l}{2^{k_i}}}{\frac{l+1}{2^{k_i}}}$ 
	   for $0 \leq l < 2^{k_i}$. Let the partition at level 
	   $k_n$ be given by 
	   \[\set{\Delta_{l}^{k_n} = \interval[open
	       left]{\frac{l}{2^{k_n}}}{\frac{l+1}{2^{k_n}}}}{0 \leq l < 2^{k_n}}.\] 
       
           If $k_1 < k_2 < \cdots < k_n$, $R_{k_i}$ for $k_i < k_n$ will be constant on each of these 
	   $\Delta_{l}^{k_n}$. Thus,
	   \begin{align*} 
	       \int\limits_{0}^{1}R_{k_1}(x)\dots R_{k_n}(x) & = \sum\limits_{l =
		   0}^{2^{k_n}-1}\int\limits_{\Delta_{l}^{k_n}}R_{k_1}(x)\dots R_{k_n}(x) \\
	       & = (R_{k_1}(x)\dots R_{k_{n-1}}(x))\int\limits_{\Delta_{0}^{k_n} + \Delta_{1}^{k_n}
	       }R_{k_n}(x) \\
	       & + \cdots + (R_{k_1}(x)\dots R_{k_{n-1}}(x))
	       \int\limits_{\Delta_{2^{k_n-1}}^{k_n} + \Delta_{2^{k_n}}^{k_n}}R_{k_n}(x)
	   \end{align*}  
	   Each of the integral is $0$ and hence the sum
	   is 0. If $k_1 = k_2 = k_3
	   \cdots = k_n$ and n is even then total integral is one otherwise integral is $0$.
       \item
	   Let us write $R_i(x) = 2*a_i - 1$ where $x = 0.a_1a_2\cdots$ is the binary
	   representation of $x$. Note that $x = \sum\limits_{i = 1}^{\infty}a_i/2^i$.
	   \begin{align*}
	       \sumInf{R_i(x)2^{-i}} &= \lim\limits_{n\to\infty}\sum\limits_{i=1}^{n}R_i(x)2^{-i} \\
	       &= \lim\limits_{n\to\infty}(2*(a_1/2 + a_2/4 + \cdots + a_n/2^n))\\ 
	       &\quad - \lim\limits_{n\to\infty}(1/2 + 1/4 + \cdots + 1/2^n) \\
	       & = 2*x - 1 
	   \end{align*}
	   We get the second term by using the definition of $R_i$, i.e $R_i(x) = 2*a_i - 1$. We can
	   split the limit because each converges. The first limit is just the binomial
	   representation of $x$ and the second is a geometric series.
    \end{enumerate}
\end{proof}
\begin{Definition}
    We define $W_N(\omega) = \finiteSum{R_k(\omega)}{k}{N}$. Then $W$ gives the total amount won or
    lost after the $N^{th}$ toss. Using the definition of $R_k$, we get
    \begin{align*}
	W_N(\omega) &= 2(a_1 + a_2 + \cdots + a_N) - N \\
	&= 2S_N(\omega) - N.
    \end{align*}
\end{Definition}
With the above definition, our condition in the set given by~\ref{eq:WLLN_lebesgue_set} becomes,
\[\lvert W_N(\omega) \rvert \leq 2\epsilon N.\]
We will need one more result before proving~\ref{thm:LLN_bernoulli_seq}. The special case of this
result will be proved later.
\begin{Proposition}\label{prop:chebychev_ineq_1}
    Let $f$ be a non-negative, piecewise constant function on $\Omega$ and $\alpha > 0 \in \R$ be a
    positive real number. Then,
    \[\measure{\set{\omega\in\Omega}{f(\omega) > \alpha}} <
	\frac{1}{\alpha}\int\limits_{0}^{1}f(\omega),\]
    where the integeral is the standard Riemann integral in $\R$.
\end{Proposition}
\begin{proof}
    Suppose $f$ is defined on the mesh $0 = \omega_{1} < \omega_{2} < \cdots < \omega_{k} = 1$ 
    such that $f(\omega) = c_i$
    whenever $\omega \in (\omega_{i},\omega_{i+1})$ for all $1 \leq i \leq k-1$.
    Then,
    \begin{align*}
	\int\limits_{0}^{1}f(\omega) &= \finiteSum{c_i({\omega}_{i+1} - {\omega}_i)}{i}{k} \\
	& \geq \finiteSumStack{c_i({\omega}_{i+1} - {\omega}_i)}{i=1}{c_i > \alpha}{k} \\
	& > \alpha \finiteSumStack{({\omega}_{i+1} - {\omega}_i)}{i=1}{c_i > \alpha}{k} \\
	& \quad = \alpha\measure{\set{\omega\in\Omega}{f(\omega) > \alpha}}.
    \end{align*}
\end{proof}
Now we are ready to prove~\ref{thm:LLN_bernoulli_seq} (1) which is the \textbf{WLLN} for Bernoulli
sequences.
\begin{proof}
    The complement of the set $\Omega_{E_N}$ is given by,
    \[\indxComp{\Omega}{E_N} = \set{\omega\in\Omega}{\lvert W_N(\omega) \rvert > 2\epsilon
	    N}.\]
    Since $\epsilon$ is arbitrary we can disregard the factor of $2$ and square both sides to
    remove the annoying absolute sign. Thus,
    \[\indxComp{\Omega}{E_N} = \set{\omega\in\Omega}{W^{2}_{N}(\omega)  >
	    N^2{\epsilon}^2}.\]
    Now we can use~\ref{prop:chebychev_ineq_1} in stating,
    \[\measure{\indxComp{\Omega}{E_N}} < 
	\frac{1}{N^2{\epsilon}^2}\int\limits_{0}^{1}W^2_N(\omega).\]
    To evaluate the integral we observe,
    \begin{align*}
	\int\limits_{0}^{1}W^2_N(\omega) &= \int\limits_{0}^{1}{(\finiteSum{R_k(\omega)}{k}{N})^2}\\
	&= \finiteSum{\int\limits_{0}^{1}R_k^2(\omega)}{k}{N} + 
	\finiteSumStack{\int\limits_{0}^{1}R_i(\omega)R_j(\omega)}{i,j=1}{i\neq j}{N}.
    \end{align*}
    The second summation is $0$ by~\ref{prop:rademacher} (1) while the first summation is $N$
    because each integral is $1$.
    Thus,
    \[\measure{\indxComp{\Omega}{E_N}} \leq \frac{1}{N^2{\epsilon}^2}N =
	\frac{1}{N{\epsilon}^2}.\]
    Thus,
    \[\atob{\measure{\indxComp{\Omega}{E_N}}}{0}\quad\text{as}\,\atob{N}{\infty}.\]

\end{proof}

We are now ready to prove~\ref{thm:LLN_bernoulli_seq} (2) which is the \textbf{SLLN} for the
Bernoulli sequence.
\begin{proof}
    We noted that to show $\measure{\indxComp{\Omega}{E}} = 0$, for any $\epsilon$ 
    we will have to find simple
    sets (closed intervals) $E_i$ such that $\indxComp{\Omega}{E} \subset \countUnion{E_i}{i}$
    and $\infiniteSum{\measure{E_i}}{i} < \epsilon$.
    There is $\delta > 0 \in \R$ such that the set,
    \[A_n = \set{\omega\in\Omega}{\lvert W_n(\omega) \rvert > \delta n}.\]
    is not empty for some $n$.
    How did we get this set? Consider an $\omega \in \indxComp{\Omega}{E}$. Then
    $\frac{S_n(\omega)}{n} \not \to \frac{1}{2}$. This is equivalent to saying,
    \[\thereIs{\delta}\forEv{N}\thereIs{n}\suchThat{n\geq
	    N}{\land}{\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} > \delta}.\]
    Since $\distR{\frac{S_n(\omega)}{n}}{\frac{1}{2}} = \lvert 
    \frac{W_n(\omega)}{n}\rvert$ the set $A_n$ is not empty.

    Moreover, $A_n$ is just a finite union of disjoint h-intervals and is Lebesgue measurable.
    By~\ref{prop:chebychev_ineq_1} (removing the absolute sign by raising to $4^{th}$ power)
    \[\measure{A_n} < \frac{1}{{\delta}^4n^4}\int\limits_{0}^1(\finiteSum{R_k}{k}{n})^4.\]	
    The integrand yields $5$ kinds of terms,
    \begin{enumerate}
	\item
	    $R_j^4$ for $j = 1 \cdots n$.
	\item
	    $R_j^2 R_k^2$ for $j\neq k$.
	\item
	    $R_j^2 R_k R_l$ for $j\neq k \neq l$.
	\item
	    $R_j^3 R_k$ for $j \neq k$.
	\item
	    $R_j R_k R_l R_m$ for $j\neq k \neq l \neq m$.
    \end{enumerate}
    Using~\ref{prop:rademacher} it is easy to observe that only the first and second kind of terms integrate
    out to $1$ while others give zero. There  are $n$ terms of the first kind and $3n(n-1)$ terms
    involving the second kind.
    Thus,
    \[\measure{A_n} < \frac{3}{n^2{\delta}^{4}}.\]
    The idea is to cover $\indxComp{\Omega}{E}$ using the sets $A_n$. Since these sets are not
    necessarily closed we can take their closure to get closed intervals without changing the
    measure. Thus it is not necessary to find closed intervals. However, we need to make sure that the
    sequence of sets decrease in measure so that the countable sum can be made arbitrarily small.
    
    For a constant $C$, set $\delta_n = Cn^{\frac{-1}{2}}$. Then,
    \[\infiniteSum{\frac{3}{{\delta_n}^4n^2}}{n} =
	\frac{3}{C}\infiniteSum{\frac{1}{n^{\frac{3}{2}}}}{n}\] 
     converges and can be made smaller than any epsilon by choosing sufficiently large $C$.

     Let,\[E_n = \set{\omega\in\Omega}{\lvert W_n(\omega)\rvert > \delta_{n}n}.\]
     If $\indxComp{\Omega}{E} \subset \countUnion{E_n}{n}$, then
     \[\measure{\indxComp{\Omega}{E}} \leq \infiniteSum{\measure{A_n}}{n} =
	 \frac{3}{C}\infiniteSum{\frac{1}{n^{\frac{3}{2}}}}{n} < \epsilon.  \]
     Thus $\measure{\indxComp{\Omega}{E}} = 0$ provided 
     $\indxComp{\Omega}{E} \subset \countUnion{E_n}{n}$. However, this is easy to see. Taking
     complement what we need to show is 
     \[\countIntersection{\indxComp{E}{n}}{n} \subset \Omega_{E}.\] This is easily verified.
\end{proof}

We have seen that remarkable observations can be made by working in a measure theoretic framework.
Such arguments are standard in probability study. We isolate a few more concepts that are essential
in probability computation. One such technique we already saw when we showed that the set $\Omega_{E}$
is Lebesgue measurable by showing that is countable union and intersection of simple sets that are
Lebesgue measurable. In general, to prove that a set is measurable w.r.t a probability measure, we need
to show that it is an event in the underlying $\sigmaAlgebra$. This is usually done by showing that
that the set is a finite (or countable) combination of countable unions and intersections of elementary
sets that are events. We show a couple of examples to highlight this idea before giving a concrete 
definition.
\begin{Example}
    Let $E$ be the event where $\infiniteSum{\frac{R_n(\omega)}{n}}{n}$ converges. This is an interesting series.
    We know that $\infiniteSum{\frac{1}{n}}{n}$ diverges but $\infiniteSum{\frac{{(-1)}^{n}}{n}}{n}$
    converges. Is $E$ a plausible event? In other words is $\Omega_{E}$ Lebesgue measurable?
    Here $\Omega_{E}$ is given by,
    \[\set{\omega\in\Omega}{\infiniteSum{\frac{R_n(\omega)}{n}}{n} < \infty}.\]
    Let $T_n(\omega) = \finiteSum{\frac{R_k(\omega)}{k}}{k}{n}$. If $\omega\in\Omega_{E}$, then
    for any $\epsilon$, there is an integer $k$ such that
    $\distR{T_n(\omega)}{T_m(\omega)} < \epsilon$ whenever $n,m \geq \epsilon$. We can get rid of
    the $\epsilon$ by finding a positive integer $r$ such that $\frac{1}{r} < \epsilon$.
    Consider the set,
    \[A_{m,n,r} = \set{\omega\in\Omega}{\distR{T_n(\omega)}{T_m(\omega)} < \frac{1}{r}}.\]
    This set is Lebesgue measurable being a union of finite h-intervals in $\Omega$. We can write
    $\Omega_{E}$ as,
    \[\Omega_{E} =
	\bigcap\limits_{r=1}^{\infty}\bigcup\limits_{k=1}^{\infty}\bigcap\limits_{m,n \geq
	    k}^{\infty}A_{m,n,r}.\]
    This shows that $\Omega_{E}$ is Lebesgue measurable.
\end{Example}
\begin{Example}
    Let $E$ be the event where a prescribed sequence, say $HTTH$, occurs infinitely often. To
    describe $\Omega_{E}$, let $E_n$ be the event where the pattern occurs beginning at the
    $n^{th}$ step. $E_n$ is described by a finite number of conditions on the Rademacher functions,
    \[\Omega_{E_n} = \set{\omega\in\Omega}{R_n(\omega) =
	    1,R_{n+1}(\omega)=-1,R_{n+2}(\omega)=-1,R_{n+3}(\omega)=1}.\]
    How do we get $\Omega_{E}$ from $\Omega_{E_n}$? Since the pattern occurs infinitely
    often, no matter what integer $k$ we choose, there should be a $n$ far out such that
    $\omega\in \Omega_{E_n}$. Thus,
    \[\Omega_{E} = \bigcap\limits_{k=1}^{\infty}\bigcup\limits_{n\geq k}^{\infty}
	\Omega_{E_n}.\]
\end{Example}
What can we say about their probabilities? 
All these examples have a general pattern. Say we have a countable collection of events $\lbrace
E_1,E_2,\cdots\rbrace$. Let $E$ be the event that infinitely many of the $E_i$'s occur. Can we
determine the probability of $E$ from the probabilities of $E_i$'s? Two famous results{\textemdash} 
the Borel-Cantelli Lemmas{\textemdash}are relevant to the answer. First we will give a description of
the term infinitely often and almost always.

For a sequence of events $\seq{E}{n}$,we define the limit superior, and limit
inferior as.
\begin{align*}
    &\limSupSet{E}{n}{k} \\
    &\limInfSet{E}{n}{k}.
\end{align*}
\begin{Remark}\label{rmk:limsup_liminf_set}
    The terminology stems from the corresponding definitions for 
    a sequence of real numbers. For example if we let $\seq{s}{n}$ to be
    a sequence of real numbers then we can make observations of their limiting behavior by looking
    at the $\sup$ and $\inf$ of the tail sets. Let us define the following,
    \begin{align*}
	u_n &= \inf\set{s_k}{k\geq n} \\
	v_n &= \sup\set{s_k}{k\geq n} \\
    \end{align*}
    Then it is easy to see that $u_1 \leq u_2 \cdots$, while $v_1 \geq v_2 \geq \cdots$. Since this
    are monotonic sequence, if they converge they will converge to their $\sup$ and $\inf$
    respectively. Thus,
    \begin{align*}
	\liminf s_n & := \lim\limits_{n\to\infty}u_n = \sup\set{u_n}{n\in \Zplus} \\
	\limsup s_n & := \lim\limits_{n\to\infty}v_n = \inf\set{v_n}{n\in \Zplus} \\
    \end{align*}	
    
    Similarly, we can define the same for sequence of sets. However, to get supremum
    and infimum, we need an order relation. This is done through the relation $\subset$. Thus if we
    have a sequence of set $\seq{E}{n}$, the $\sup$ is defined as $\countUnion{E}{n}$. This is easy
    to see; as for any $n$, $E_n \subset \countUnion{E}{n}$. Similarly, the $\inf$ is defined
    as $\countIntersection{E}{n}$.   

    Now analogously we can define,
    \begin{align*}
	U_n &= \inf\set{E_k}{k\geq n} \\
	V_n &= \sup\set{E_k}{k\geq n} \\
    \end{align*}
    Thus, we have $U_1 \subset U_2 \subset U_3 \cdots$, while $V_1 \supset V_2 \supset V_3 \cdots$.
    Thus we see that $\atobUp{U_n}{\countUnion{U_n}{n}}$ while 
    $\atobDown{V_n}{\countIntersection{V_n}{n}}$. Hence,
    \begin{align*}
	\liminf E_n & := \lim\limits_{n\to\infty}U_n = \sup\set{U_n}{n\in \Zplus} \\
	\limsup E_n & := \lim\limits_{n\to\infty}V_n = \inf\set{V_n}{n\in \Zplus} \\
    \end{align*}	
    

    In probability, we denote the $\limsup E_n$ as the set $\lbrace E_n \quad \text{i.o}\rbrace$
    where the i.o stands for \textbf{infinitely often}. This is from the fact that if $\omega \in
    \limsup E_n$, then for any $n$ there is a $k$ such that $\omega \in E_k$. Thus no matter how far
    out we go, we can \emph{find} a $k$ farther such that $\omega \in E_k$. Hence, $\limsup E_n$ is
    the event that gives the point in $\Omega$ which are in infinitely many of the events.

    We denote the set $\liminf E_n$ as the set $\lbrace E_n \quad \text{a.a}\rbrace$ where the a.a
    stands for \textbf{almost always}. This is from the fact that if $\omega \in \liminf E_n$, then
    there is an $n$ such that for any $k$ greater than $n$, $\omega \in E_k$. Thus, $\liminf E_n$ is
    the event that all but a finite number of events occur. 

    If $\limsup E_n = \liminf E_n = E$, then we say that $\limit{E_n}{n}{\infty} = E$.
\end{Remark}
We will need the following result.
\begin{Proposition}\label{prop:prob_meas_limsup_liminf}
    Let $\probS$ be a probability space. If $\lbrace E_n \rbrace \subset \algebra{F}$ is a countable
    collection of events, then
    \[\probMeasure{\liminf E_n} \leq \liminf \probMeasure{E_n} \leq \limsup \probMeasure{E_n} \leq
	\probMeasure{\limsup E_n}.\]
\end{Proposition}
\begin{proof}
    Note that $(\probMeasure{E_n})$ is a sequence of positive numbers and so the middle inequality
    is trivial. First let us show that,
    \[\probMeasure{\liminf E_n} \leq \liminf \probMeasure{E_n}.\]
    Consider the set,
    \[U_n = \inf\set{E_k}{k\geq n} = \bigcap\limits_{k\geq n}E_k.\]
    Then, by~\ref{rmk:limsup_liminf_set}, $\seq{U}{n}$ is an increasing sequence, and by the properties
    of a measure (see~\ref{thm:prop_of_meas}),
    \[\probMeasure{\liminf E_n} = \probMeasure{\countUnion{U_n}{n}}
	=\lim\limits_{n\to\infty}\probMeasure{U_n}.\]
    Since $U_n \subset E_k$ for all $k \geq n$, $\probMeasure{U_n} \leq \probMeasure{E_k}$ for all
    $k\geq n$. Thus,
    \[\probMeasure{U_n} \leq \inf\set{\probMeasure{E_k}}{k\geq n}.\]
    Hence, taking limits
    \[\lim\limits_{n\to\infty} \probMeasure{U_n} \leq
	\lim\limits_{n\to\infty}\inf\set{\probMeasure{E_k}}{k\geq n} = \liminf\probMeasure{E_n}.\]
    We get the other inequality using an analogous argument.
\end{proof}

\begin{Theorem}[name=Continuity of Probability measure]\label{thm:continuity_prob_measure}
    Let $\set{E_n}{n\in\Zplus}$ be a countable collection of events in a probability space $\probS$.
    If $E = \lim\limits_{n\to\infty}E_n$, then $\limit{\probMeasure{E_n}}{n}{\infty} = \probMeasure{E}$. 
\end{Theorem}
\begin{proof}
    Since $\lim\limits_{n\to\infty}E_n = \limsup E_n = \liminf E_n$,
    using~\ref{prop:prob_meas_limsup_liminf} we get the desired result. This theorem highlights the
    continuity of the probability measure since,
    \[\limit{\probMeasure{E_n}}{n}{\infty} = \probMeasure{\lim\limits_{n\to\infty}E_n},\]
    interchanges the limit operation.
\end{proof}
\begin{Theorem}[name=First Borel-Cantelli Lemma]\label{thm:borel_cantelli_1}
    Given a probability space $\probS$ and a countable collection of events, $\lbrace E_n \rbrace
    \subset \algebra{F}$, let $E = \lbrace E_n \,\text{i.o}\rbrace$. Then,
    \[\text{If}\,\infiniteSum{\probMeasure{E_n}}{n} < \infty\quad\text{then}\, \probMeasure{E} = 0.\]
\end{Theorem}
\begin{proof}
    Let $V_n = \bigcup\limits_{k\geq n}E_k$. Then $E = \countIntersection{V_n}{n}$. Thus $E \subset
    V_n$ for every $n$. Now,
    \[\probMeasure{V_n} \leq \series{\probMeasure{E_k}}{k}{n}{\infty}.\]
    Since, $\infiniteSum{\probMeasure{E_n}}{n} < \infty$, for any $\epsilon$, there is an $N$ such
    that $\series{\probMeasure{E_k}}{k}{N}{\infty} < \epsilon$. Thus,
    \[\probMeasure{E} \leq \probMeasure{V_N} \leq 
	\series{\probMeasure{E_k}}{k}{N}{\infty} < \epsilon.\]
    Since $\epsilon$ was arbitrary we get the result.
\end{proof}
\begin{Example}[name=Run lengths]
    Consider the probability space $\probS$, where $\Omega = \hInt{0}{1}$, $\algebra{F}$ is the
    collection of Lebesgue measurable sets in $\Omega$ and $\probMeas = \mu$ is the Lebesgue
    measure. Thus we are in the Borel space of describing infinite coin tosses. For any $n$ define
    the run length function $l_n$ by,
    \begin{equation*}
	l_n(\omega) = \# \,\text{consecutive $1$'s in the binary expansion of $\omega$ starting at
	    the $n^{th}$ place}.
    \end{equation*}
    Thus $l_n(\omega) = k$ if,\[R_{n(\omega)} = 1, R_{n+1}(\omega) = 1,\ldots,R_{n+k-1} = 1,R_{n+k} =
	-1.\]
    A run length function gives us the number of consective heads in a sequence $\omega$ of
    infinite coin tosses. Take a sequence of non-negative integers $r_1,r_2,r_3,\ldots$ and let
    $E_n$ be the event that we have atleast $r_n$ consecutive heads starting at the $n^{th}$ toss. 
    Then, 
    \[\Omega_{E_n} = \set{\omega\in\Omega}{R_{n(\omega)} = 1, R_{n+1}(\omega) = 1,\ldots,R_{n+r_n-1} 
	    = 1}.\]
    Let $E = \lbrace E_n\,\text{i.o} \rbrace$. Then,
    \[P(E_n) = \measure{\Omega_{E_n}} = {(\frac{1}{2})}^{r_n}.\]
    By~\ref{thm:borel_cantelli_1}, if $\infiniteSum{{\left(\frac{1}{2}\right)}^{r_n}}{n} < \infty$, then
    $P(E) = 0$. As a concrete case take $r_n = n$. Then the probability of the event that consists
    of $n$ consecutive heads starting at the $n^{th}$ toss, infinitely often, is $0$.
\end{Example}
Next we define conditional probability and independence of events in a probability space.
\begin{Definition}[name=Conditional probability measure]
    Suppose $A,B$ are events in a probability space $\probS$ with $\probMeas(B) > 0$. The
    conditional probability (measure) of $A$ given $B$ is 
    \[\probMeasure{A|B} = \frac{\probMeasure{A\cap B}}{\probMeasure{B}}.\]
\end{Definition}
\begin{Remark}
    Fix an event $B \in \algebra{F}$. Then the the conditional probability measure is a 
    function $\map{\probMeasure{.|B}}{\algebra{F}}{\extRealsPos}$. Recall that $\algebra{F}_{B}$ is the
    restricted sigma algebra. See~\ref{ex:type_of_sigma_alg}. If we restrict the sample space to $B$, the measure space
    $\measureS{B}{\algebra{F}_{B}}{\probMeasure{.|B}}$ becomes a probability space. This is proved in the
    following theorem.
\end{Remark}
\begin{Theorem}[name=Conditioned probability space]
    Let $\probS$ be a probability space. For an given $B \in \algebra{F}$, 
    $\measureS{B}{\algebra{F}_{B}}{\probMeasure{.|B}}$ is also a probability space.
\end{Theorem}
\begin{proof}
    Note that $\algebra{F}_{B} = \set{E\cap B}{E \in \algebra{F}}$ is a $\sigmaAlgebra$.
    Clearly, $\cProbMeasure{\emptyset}{B} = 0$. Also,
    \[\cProbMeasure{B}{B} = \frac{\probMeasure{B\cap B}}{\probMeasure{B}} = 1.\]
    Now, let $\lbrace A_i \rbrace \subset \algebra{F}_{B}$ be a sequence of pairwise disjoint sets in the
    restricted sigma algebra $\algebra{F}_{B}$.
    \begin{align*}
	\cProbMeasure{(\countDisjUnion{A_i}{i})}{B} &= 
	\frac{\probMeasure{(\countDisjUnion{A_i}{i})\cap B}}{\probMeasure{B}} \\
	&= \frac{\probMeasure{\countDisjUnion{(A_i\cap B)}{i}}}{\probMeasure{B}} \\
	&= \frac{\infiniteSum{\probMeasure{(A_i\cap B)}}{i}}{\probMeasure{B}} \\
	&= \infiniteSum{\cProbMeasure{A_i}{B}}{i} \\
    \end{align*}
\end{proof}
The conditional probability measure of an event $A$ in a sample space, given the probability measure of an
event $B$ in a sample space corresponds to probability of event $A$ occuring knowing that $B$ has occured. We
give an example below to highlight this, i.e knowing that $B$ has occured, our sample space is now the
restricted probability space $\measureS{B}{\algebra{F}_{B}}{\probMeasure{.|B}}$. Hence calculating the
probability of $A$ is calculating the conditional probability measure of $A$ given $B$.
\begin{Example}\label{ex:independece_2_events}
    Let $\mathcal{B}$ be the probabilistic space of the Bernoulli sequence of infinite coin tosses. Let $A$ be
    the event that we tossed two consecutive Heads, and $B$ be the event that the first toss was head. What is
    the probability that $A$ occured given that $B$ occured? Recall that our  probability space $\probS$ 
    is given by $\Omega = \hInt{0}{1}$, $\algebra{F} = \text{Lebesgue measurable sets in $\Omega$}$, 
    and $\probMeas = \mu$, the Lebesgue measure.

    Since $B$ occured, we need to calulate $P(A|B)$. With $A$ we identify the corresponding set in the sigma
    algebra as \[\Omega_{A} = \set{\omega\in\Omega}{R_1(\omega) = 1,R_2(\omega) =1}.\]
    Hence $P(A) = \measure{\Omega_{A}} = \measure{\hInt{\frac{3}{4}}{1}} = \frac{1}{4}$.
    Similary $P(B) = \measure{\Omega_{B}} = \measure{\hInt{\frac{1}{2}}{1}} = \frac{1}{2}$.
    Thus \[P(A | B) = \measure{\Omega_A|\Omega_B} = 
	\frac{\measure{\Omega_{A} \cap \Omega_{B}}}{\measure{\Omega_{B}}} = \frac{1}{2}.\]
\end{Example}
The following theorem is very important whose proof is almost trivial.
\begin{Theorem}[name=Total probability theorem]\label{thm:total_prob_thm}
    Let $\probS$ be a probability space. If $\lbrace H_i \rbrace $ is a countable collection of pairwise
    disjoint events such that $\probMeasure{H_i} \neq 0$ for all $i$ and $\countUnion{H_i}{i} = \Omega$, 
    then for any event $A \in \algebra{F}$,
    \[\probMeasure{A} = \infiniteSum{\cProbMeasure{A}{H_i}\probMeasure{H_i}}{i}.\]
\end{Theorem}
\begin{proof}
    Since $A \subset \Omega$, we can observe that $ A \subset \countDisjUnion{H_i}{i}$. 
    Thus $A = \countDisjUnion{(A\cap H_i)}{i}$.
    Hence,
    \begin{align*}
	\probMeasure{A} &= \probMeasure{\countDisjUnion{(A\cap H_i)}{i}} \\
	& = \infiniteSum{\probMeasure{A\cap H_i}}{i} \\
	& = \infiniteSum{\cProbMeasure{A}{H_i}\probMeasure{H_i}}{i}.
    \end{align*}
\end{proof}
If knowing that $B$ occured doesn't change the probability of $A$, then we know that $A$ and $B$ are
independent. For example if $B$ is event that the first coin toss is a Head and $A$ is the event that the
second toss also a Head, then $A$ is independent of $B$. That is $P(A | B) = P(A)$.
We make this notion precise w.r.t a probability space.
\begin{Definition}[name=Independence of events]
    Given a probability space $\probS$, two events $A,B$ are independent if
    \[\probMeasure{A\cap B} = \probMeasure{A}\probMeasure{B}.\]
\end{Definition}
Note that in~\ref{ex:independece_2_events}, the events $A,B$ are NOT independent. Also, observe that the 
definition is symmetric.  
\begin{Proposition}
    If $A_1,A_2$ are independent events in a probability space $\probS$, then so are $\indxComp{A}{1}$ and
    $A_2$.
\end{Proposition}
\begin{proof}
    Note that, $A_2 = (A_2\cap A_1) \disjU (A_2 \cap \indxComp{A}{1})$. Thus,
    \begin{align*}
	&\probMeasure{A_2} = \probMeasure{A_2\cap A_1} + \probMeasure{A_2 \cap \indxComp{A}{1}} \\
	&\implies \probMeasure{A_2} - \probMeasure{A_2\cap A_1} = \probMeasure{A_2 \cap \indxComp{A}{1}} \\
	&\implies \probMeasure{A_2} - \probMeasure{A_2}\probMeasure{A_1} = 
	\probMeasure{A_2 \cap \indxComp{A}{1}} \\
	&\implies \probMeasure{A_2}(1 - \probMeasure{A_1}) = \probMeasure{A_2 \cap \indxComp{A}{1}} \\
	&\implies \probMeasure{A_2}\probMeasure{\indxComp{A}{1}} = \probMeasure{A_2 \cap \indxComp{A}{1}}
    \end{align*}
\end{proof}
We extend this idea for a collection of events.
\begin{Definition}[name=Independence of a collection of events and sigma algebras]
    A collection of events $\lbrace A_i \rbrace$ are independent if for each $n\in\Zplus$ and each selection
    of integers, $1\leq i_1 < i_2 < \cdots < i_k\leq n$,
    \[\probMeasure{A_{i_1}\cap\ldots\cap A_{i_k}} = \finiteProduct{\probMeasure{A_{i_j}}}{j}{k}.\]
    We say a collection of $\sigmaAlgebra$s $\lbrace \algebra{F}_i\rbrace$ are independent if each collection
    of events chosen individually from the $\sigmaAlgebra$s are independent.
\end{Definition}
\begin{Example}
    Three events $A,B,C$ in the probability space $\probS$ are independent if
    \begin{enumerate}
	\item
	    $\probMeasure{A\cap B} = \probMeasure{A}\probMeasure{B}$.
	\item
	    $\probMeasure{A\cap C} = \probMeasure{A}\probMeasure{C}$.
	\item
	    $\probMeasure{B\cap C} = \probMeasure{B}\probMeasure{C}$.
	\item
	    $\probMeasure{A\cap B\cap C} = \probMeasure{A}\probMeasure{B}\probMeasure{C}$.
    \end{enumerate}
\end{Example}
\begin{Example}
    Let $H_i$ be the event that the $i^{th}$ toss is a head in the space of Bernoulli sequences $\mathcal{B}$.
    Easy to check that the corresponding events $\Omega_{H_i} = \set{\omega\in\Omega}{R_i(\omega) = 1}$ 
    are independent.
\end{Example}
\begin{Proposition}
    If $\lbrace A_i\rbrace$ are independent then so are $\lbrace \indxComp{A}{i} \rbrace$.
\end{Proposition}
\begin{Theorem}[name=Second Borel-Cantelli Lemma]\label{thm:borel_cantelli_2}
    Let $\probS$ be a probability space and $\lbrace A_i \rbrace$ be a collection of independent events. Let
    $A =\lbrace A_n \,\text{i.o}\rbrace$. 
    \[\text{If}\,\infiniteSum{\probMeasure{A_i}}{i} = \infty\quad \text{then}\,\probMeasure{A} = 1.\]
\end{Theorem}
\begin{proof}
    $A = \limSupSet{A}{k}{n}$ and so $\comp{A} = \bigcup\limits_{k=1}\bigcap\limits_{n\geq k}\indxComp{A}{n}$.
    To show that $\probMeasure{A} = 1$, we will show that 
    $\probMeasure{\comp{A}} = 0$. It suffices to show that 
    $\probMeasure{\bigcap\limits_{n\geq k}\indxComp{A}{n}} = 0$ for all $k$. Due to independence,
    \[\probMeasure{\bigcap\limits_{n\geq k}^{l}\indxComp{A}{n}} =
	\prod\limits_{n=k}^{l}\probMeasure{\indxComp{A}{n}}.\]
    Now, $\probMeasure{\indxComp{A}{n}} = 1 - \probMeasure{A_n}$. Since $1-x\leq e^{-x}$,
    $\probMeasure{\indxComp{A}{n}} = 1 - \probMeasure{A_n} \leq e^{-\probMeasure{A_n}}$. Hence,
    \[\probMeasure{\bigcap\limits_{n\geq k}^{l}\indxComp{A}{n}} \leq
	\prod\limits_{n=k}^{l}e^{-\probMeasure{A_n}} = e^{-\sum\limits_{n=k}^{l}\probMeasure{A_n}}.\]
    Thus, as $\atob{l}{\infty}$, $\atob{\probMeasure{\indxComp{A}{n}}}{0}$.
\end{proof}
\begin{Example}\label{ex:borel_cantelli_2_ex1}
    Let $H_n$ be the event of a head at the $n^{th}$ toss. The corresponding event in the $\sigmaAlgebra$
    is\[\Omega_{H_n} = \set{\omega\in\Omega}{R_n(\omega) = 1}.\]
    Furthermore, $\probMeasure{\Omega_{H_n}} = \frac{1}{2}$. Since $\infiniteSum{\frac{1}{2}}{i} = \infty$,
    the probability that we see Heads infinitely often is $0$.
\end{Example}
\begin{Example}
    Any finite pattern in an infinite sequence of coin tosses occurs infinitely often with probability of $1$.
    To see a concrete case, consider the sequence $HTTH$. Let $E_n$ be the event where $HHTH$ occur starting
    at step $n$ and let $\Omega_{E_n}$ be the corresponding set in the $\sigmaAlgebra$. Then 
    \[\Omega_{E_n} = \Omega_{H_n}\cap\indxComp{\Omega}{H_{n+1}}
	\cap\indxComp{\Omega}{H_{n+2}}\cap\Omega_{H_{n+3}},\]
    where $\Omega_{H_n}$ is described in~\ref{ex:borel_cantelli_2_ex1}. From independence 
    $\probMeasure{\Omega_{E_n}} = \frac{1}{2^4}$.
    Since $\Omega_{E_n}$ and $\Omega_{E_{n+1}}$ are not independent we cannot
    apply~\ref{thm:borel_cantelli_2}. However, $\lbrace \Omega_{E_n},
    \Omega_{E_{n+4}},\Omega_{E_{n+8}},\cdots\rbrace$ are independent that satisy,
    \[\infiniteSum{\probMeasure{\Omega_{E_{4n+1}}}}{n} = \infty.\]
    So, $\probMeasure{\lbrace \Omega_{E_{4n+1}}\,\text{i.o} \rbrace } = 1$. But,
    \[\lbrace \Omega_{E_{4n+1}}\,\text{i.o} \rbrace \subset 
	\lbrace \Omega_{E_{n}}\,\text{i.o} \rbrace.\]
    Hence, $\probMeasure{\Omega_{E_{n}}\,\text{i.o} \rbrace} = 1$, since probability measure of any event
    is bounded by $1$.
\end{Example}
From now onwards, we will not be explicit in stating an underlying probabilistic process. We will denote the
probability of an event by its probability measure.
