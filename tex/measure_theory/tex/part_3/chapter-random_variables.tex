\chapter{Random Variables and Expectation}
\section{Random variables and their distributions}
Let $\probS$ be a probability space and let $\metricS{\mbbY}{\algebra{N}}$ be a measure space. A
$\measMap{\family{F}}{\algebra{N}}$ function $X$ is called a $\mbbY$ valued random variable.
In particular for $\mbbY = \R$ or $\mbbY = \Rn$ we have the following definition,
\begin{Definition}[name=Random variable]
    A random variable (r.v) $X$ is a real valued 
    $\measMap{\algebra{F}}{\borelS{\R}}$ measurable function that maps from $\probS$ into
    $\metricS{\R}{\borelS{\R}}$. A random vector $X$ is a vector valued $\measMap{\family{F}}{\borelS{\Rn}}$
    function that maps from $\probS$ into $\metricS{\Rn}{\borelS{\Rn}}$.
\end{Definition}
As always, we wish to discard the importance of behavior of sets of measure zero.
\begin{Definition}[name=Almost surely]
    Suppose $X,Y$ are two random variables on the same probability space. Then $X = Y$ a.s.~or $X = Y$ almost
    surely, means that,
    $\probMeasure{\set{\omega\in\Omega}{X(\omega) \neq Y(\omega)} }= 0$.
\end{Definition}
Note, almost surely is precisely what is meant by almost everywhere that was defined for a general measure
space.
\begin{Example}
    Consider the space $\mcalB$ of Bernoulli sequence and the corresponding measure space $\Omega = \hInt{0}{1}$
    with the Lebesgue measure $\mu$. Any Rademacher function $R_n$ which maps from
    $\measureS{\hInt{0}{1}}{\family{L}}{\mu}$ into $\metricS{\R}{\borelS{\R}}$ 
    is a random variable because for any $E\in\borelS{\R}$, 
    $\invImIndx{R}{n}{E} = \set{\omega\in\hInt{0}{1}}{R_n(\omega)\in E}$ is a finite union of
    intervals. Similarly $W_N$ is a random variable.
\end{Example}
\begin{Example}
    Consider the space $\mcalB$ of Bernoulli sequence and let $X$ be a function from
    $\setDiff{\mcalB}{\mcalB_{\text{neg}}}$ in to $\hInt{0}{1}$ defined by,
    \[X(b_1,b_2,b_3,\dots) = 0.\omega_1\omega_2\dots,\]
    where $\omega_i = 1$ if $b_i$ is a head $H$, $\omega_i = 0$ if $b_i$ is a tails $T$. Then $X$ is a random
    variable. Thus a random variable \emph{transforms} a probabilistic process to a measure space.
\end{Example}
\begin{Proposition}
    Let $X$ be a r.v.~from a probability space $\probS$ to a measure space $\metricS{\mbbY}{\algebra{N}}$.
    Let $\indMeas{\probMeas}{X}$ be the induced measure in $\metricS{\mbbY}{\algebra{N}}$. Then, 
    $\measureS{\mbbY}{\algebra{N}}{\indMeas{\probMeas}{X}}$ is a probability space.  
\end{Proposition}
\begin{proof}
    By~\ref{prop:induced_meas}, we know that $\measureS{\mbbY}{\algebra{N}}{\indMeas{\probMeas}{X}}$ is a
    measure space. Hence, we only need to check if $\indMeasure{\probMeas}{X}{\mbbY} = 1$. Indeed
    $\invIm{X}{\mbbY} = \Omega$ and $\probMeasure{\Omega} =1$, and thus we see that
    $\measureS{\mbbY}{\algebra{N}}{\indMeas{\probMeas}{X}}$ is a probability space.
\end{proof}
\begin{Definition}[name=Distribution]
    The probability measure $\indMeas{\probMeas}{X}$ on $\metricS{\mbbY}{\algebra{N}}$ is called the
    distribution of the r.v.~X and is said to be induced by $X$. 
\end{Definition}
\begin{Theorem}\label{thm:rv_equal_ae_distribution}
    Suppose $X,Y$ are two r.v.~mapping a (complete) probability space $\probS$ to a measurable space
    $\metricS{\mbbY}{\famN}$, 
    such that $X=Y$ a.s.~Then $X,Y$ have the same distribution.
\end{Theorem}
\begin{proof}
    Let $N = \set{\omega\in\Omega}{X(\omega) \neq Y(\omega)}$. Then, by our assumption, $\probMeasure{N} = 0$.
    Let $B \in \famN$ be arbitrary. Then \[\invIm{X}{B} = (\invIm{X}{B}\cap N) \disjU
    (\invIm{X}{B}\cap\comp{N}).\]
    Thus,
    \begin{align*}
	\indMeasure{\probMeas}{X}{B} &= \probMeasure{\invIm{X}{B}} \\  
	& = \probMeasure{\invIm{X}{B}\cap N} + \probMeasure{\invIm{X}{B}\cap\comp{N}} \\
	& \leq 0 + \probMeasure{\invIm{Y}{B}}\\
	&\quad = \indMeasure{\probMeas}{Y}{B}
    \end{align*}
    Similarly, $\indMeasure{\probMeas}{Y}{B} \leq \indMeasure{\probMeas}{X}{B}$.
\end{proof}

Even when we don't have a complete probability space, we can easily complete it by~\ref{thm:comp_of_meas}.
Hence we can easily forget if the probability space is complete or not. We have seen that there are 
two notions of equality for a random variable. 
\begin{Definition}
    Two r.v.~s $X,Y$ are equal in distribution if for all $B \in \famN$, 
    \[\probMeas{\lbrace X\in B \rbrace} = \probMeas{\lbrace Y\in B\rbrace}.\]
\end{Definition}
Note that the set ${\lbrace X\in B \rbrace}$ is shorthand for the set $\set{\omega\in\Omega}{X(\omega)\in B}$.
\begin{Definition}
Two r.v.~s $X,Y$ are equal a.s.~if 
\[\probMeasure{\set{\omega}{X(\omega)=Y(\omega)}} = 1.\]
\end{Definition}
By~\ref{thm:rv_equal_ae_distribution}, we know that if two random variables are equal almost surely, then they
are equal in distribution.
However the converse is not true as the following example illustrates.
\begin{Example}
    Toss a fair coin and set $X$ to be $1$ if the outcome is heads and $0$ otherwise, and let $Y$ be $0$ if
    the outcome is heads and $1$ otherwise. Then, $\probMeas{X=1} = \probMeas{X=0} = \frac{1}{2}$. Similarly,
    $\probMeas{Y=1} = \probMeas{Y=0} = \frac{1}{2}$. So that $X$ and $Y$ are equal in distribution but are not
    equal almost surely.
\end{Example}

Given a r.v.~induces probability measure on its co-domain, we can define new r.v on the range. We have the
following relationship,
\begin{Proposition}
    Let $X$ be $\mbbY$ valued r.v.~from a probability space $\probS$ to a 
    measurable space $\metricS{\mbbY}{\famN}$. Let $Y$ be a $\measMap{\famN}{\famO}$ 
    function from $\metricS{\mbbY}{\famN}$ in to $\metricS{\mbbW}{\famO}$. Let $\indMeas{\probMeas}{X}$ be the
    distribution on $\metricS{\mbbY}{\famN}$. Then $Y$ is a $\mbbW$ valued r.v.~on
    $\measureS{\mbbY}{\famN}{\indMeas{\mbbP}{X}}$ with the same distribution as the $\mbbW$ valued
    r.v.~$\fog{Y}{X}$ on $\probS$.
\end{Proposition}
\begin{proof}
    It follows the same ideas as in~\ref{prop:composition_meas_func}.
\end{proof}
Since a r.v.~is a measurable function, all the
properties in~\ref{prop:prop0_mfunc_composition_cont}-\ref{prop:prop4_mfunc_ae_limit} apply to a r.v.
We now specialize to the case of random variables mapping into $\metricS{\R}{\borelS{\R}}$. From now on, 
each r.v.~is a measurable mapping in to the reals (or extended reals). Thus we fix the following notations
that will be used throughout. 

\[\text{Probability space:} \probS,\]
\[\text{Random variable $X$:}\famF-\text{measurable mapping}.\]

Clearly for every Borel set $B \in \borelS{\R}$, $\invIm{X}{B} \in \famF$. What is the smallest sigma-algebra
on $\Omega$ on which $X$ is measurable? If we just collect the iverse image of $X$ in $\famF$, the collection
is the pre-image sigma algebra~\ref{thm:pre_img_sigma} and by definition $X$ is measurable on that sigma
algebra. 

\begin{Definition}
    If $X$ is a random variable on $\probS$, then $\sigma{X}$ is the smallest 
    sigma-algebra on $\Omega$ for which $X$
    is $\sigma{X}$-measurable.
\end{Definition}
By the remarks preceeding the definition, it is not hard to see that
\begin{Proposition}
    $\sigma{X}$ consists exactly the sets of the form $\invIm{X}{B}$ for some $B \in \borelS{\R}$. 
\end{Proposition}
\begin{proof}
    Since $\sigma{X}$ is the sigma-algebra for which $X$ is $\sigma{X}$-measurable, it must consists of all the
    sets of the form $\invIm{X}{B}$ for some borel set $B$. But the collection of all such sets is a sigma
    algebra (pre-image sigma-algebra) and $\sigma{X}$ being the smallest such set, it cannot contain any other
    type of sets. Thus, $\sigma{X} = \invIm{X}{\borelS{\R}}$.
\end{proof}
\begin{Remark}
Given a collection of random variables on $\probS$, $\famC=\set{X_{\alpha}}{\alpha \in A, X_{\alpha} r.v}$,
what is the smallest sigma algebra that makes each $X_{\alpha}$ measurable on it. From our discussions on
product sigma algebra it is not hard to see that
\[\sigmaGen{\bigcup\limits_{\alpha \in A}\sigma{X_\alpha}},\]
is the smallest sigma-algebra on which each $X_{\alpha}$ is measurable. This, along with the fact that,
$\borelS{\Rn} = \fProdSigma{\borelS{\R}}{1}{n}$, gives us the first part of the following result
\end{Remark}
\begin{Theorem}
    Let $\vect{X} = (X_1,X_2,\dots,X_n)$ be a random vector on $\probS$. Then,
    \begin{enumerate}
	\item
	    \[\sigma{\vect{X}} = \sigmaGen{\finiteUnion{\sigma{X_i}}{i}{n}}.\]
	\item
	    In order that a r.v.~$Y$ be $\sigma{\vect{X}}$-measurable, it is necessary and sufficient that
	    there exists a measurable map $\map{f}{\Rn}{\R}$ such that
	    \[Y = \fog{f}{X}. \]
    \end{enumerate}
\end{Theorem}


\subsection{Distribution Functions}
\begin{Definition}[name= (Probability) Distribution function]
    A real valued function $F$ defined on $\R$ is a (probability) distribution function if it is 
    monotone increasing, right
    continuous, and 
    \[\limit{F(x)}{x}{-\infty} = 0,\quad \limit{F(x)}{x}{\infty} = 1.\]
\end{Definition}

\begin{Definition}
    Let $X$ be a r.v.~on $\probS$. The distribution function (d.f.~) of $X$, denoted by $F_X$, is given by
    \[F(x) = \probMeas(X\leq x),\] for each $x \in \R$.
\end{Definition}
\begin{Theorem}
    Let $X$ be a r.v.~and let $F_X$ be its d.f. Then, 
    \begin{enumerate}
	\item
	    $F_X$ is non-decreasing, right continuous, real valued function with left hand limits given by,
	    \[F_X(x-) = \lim\limits_{\atobUp{x_n}{x}}F(x_n).\]
	\item
	    \[\limit{F(x)}{x}{-\infty} = 0,\quad \limit{F(x)}{x}{\infty} = 1.\]
	\item
	    $F_X$ has at most a countable number of discontinuities.
    \end{enumerate}
\end{Theorem}
See the appendix for the proof of this theorem and other facts about distribution functions. 
Given a probability measure $\probMeas$ on $\R$, we can always define a distribution function
$\map{F}{\R}{\interval{0}{1}}$ as $F(x) = \probMeasure{\hInt{-\infty}{x}}$ and vice versa
by~\ref{thm:borel_measure_R}. Thus if we have a probability space $\probS$ and a r.v.~on it, we get an induced
probability measure (distribution) $\indMeas{\probMeas}{X}$ on $\metricS{\R}{\borelS{\R}}$,
which then corresponds to a distribution function $\map{F_X}{\R}{\interval{0}{1}}$ and is 
given by $F_X(x) = \indMeasure{\probMeas}{X}{\interval{-\infty}{x}}$.
Thus,
\[X \leadsto F_X.\]
Is the converse true, i.e.
\[F \leadsto X_F?\]
That is, given a distribution function on $\R$, is there a r.v.~$X$ on some probability space such that $F_X =
F$?
The following theorem due to Skorohod answers this question.
\begin{Theorem}\label{thm:distribution_func_to_rv}
    If a function $\map{F}{\R}{\interval{0}{1}}$ is a distribution function, then there exists a
    r.v.~$\map{X}{\interval{0}{1}}{\R}$ defined
    on the probability space $\measureS{\interval{0}{1}}{\famL_{\interval{0}{1}}}{\mu}$ such that $F = F_X$,
    where $\famL_{\interval{0}{1}}$ is the family of Lebesgue measurable sets on $\interval{0}{1}$ and $\mu$
    is the corresponding Lebesgue measure.
\end{Theorem}
\begin{proof}
    Let us define $\map{X}{\interval{0}{1}}{\R}$ by,
    \[X(\omega) = \inf\set{x\in\R}{F(x)\geq \omega},\quad 0\leq\omega\leq 1.\]
    First, we will show that $X$ is a $\measMap{\famL_{\interval{0}{1}}}{\borelS{\R}}$ function and hence a 
    r.v. Fix an $a \in \R$ and consider the set $\fCompA{X}{\leq}{a}$. Since $F$ is increasing this set is
    just an interval $\interval{0}{c}$ where $c$ is the $\sup\set{\omega}{X(\omega)\leq a}$. Hence $X$ is a r.v.

    To show that $F = F_X$ we need to show that for any $y\in \R$,
    \begin{align*}
	F(y) = F_X(y) &= \indMeasure{\mu}{X}{\hInt{-\infty}{y}},\\
	& = \measure{\invIm{X}{\hInt{-\infty}{y}}},\\
	& = \measure{\set{\omega\in\Omega}{X(\omega)\leq y}}.
    \end{align*}
    Let $A = \set{\omega}{X(\omega)\leq y}$. Then $A = \interval{0}{c}$ where 
    $c = \sup\set{\omega}{X(\omega)\leq y}$. Hence $\measure{A} = c$. Thus we need
    to show that $F(y) = c = \sup\set{\omega}{X(\omega)\leq y}$.
    First note that if $\omega = F(y)$ then $X(\omega) = y$ because $F$ is increasing. Thus $F(y) \in A$. If
    we show that $F(y)$ is an upper bound for $A$, then we are done. If $\omega \in A$, then $X(\omega) \leq
    y$. Thus $F(X(\omega)) \leq F(y)$. Since $F$ is right continuous at $X(\omega)$, for any $\epsilon$ there
    is a $\delta$ such that $F(X(\omega) + \delta) - F(X(\omega)) < \epsilon$. Now $X(\omega)$ is the infimum
    of all those $x \in \R$ such that $F(x) \geq \omega$. Hence by definition of infimum, 
    there is an $x_0 \in\R$ such that $x_0 <
    X(\omega) + \delta$ and $F(x_0) \geq \omega$. Thus, because $F$ is increasing,
    \[F(X(\omega)+\delta) \geq F(x_0) \geq \omega.\]
    Hence $\omega < \epsilon + F(X(\omega))$. Since $\epsilon$ was arbitrary we get $\omega \leq
    F(X(\omega))$. Hence $F(y)$ is an upper bound for $A$.
\end{proof}
For an random vector $\vect{X} = (X_1,X_2,\dots,X_n)$, we can define its d.f.~as in~\ref{thm:borel_meas_rn}.
\begin{Definition}[name=Joint Distribution]
    Let $\vect{X}$ be a random vector $X = (X_1,X_2,\dots,X_n)$, where each $X_i$ is a r.v. We define the
    d.f.~of $\vect{X}$ as,
    \[F_{\vect{X}}(\vect{x}) = 
	\probMeasure{\set{\omega\in\Omega}{X_i(\omega) < x_i,\hspace{0.05in}1\leq i \leq n}},\]
    where $\vect{x} = (x_1,x_2,\dots,x_n)$. $F_{\vect{X}}$ is called the joint distribution of
    $X_1,X_2,\dots,X_n$.
\end{Definition}
Note that the distribution $\probMeas_{\vect{X}}(B)$ is defined as $\probMeasure{X \in B}$ for any $B \in
\borelS{\Rn}$. Since $\Rn$ is generated by generalized half-rectangles $\hInt{\vect{a}}{\vect{b}}$, we can
write
\[F_X(\vect{x}) = \probMeas_{\vect{X}}{\hInt{-\infty}{\vect{x}}},\]
where $\hInt{-\infty}{\vect{x}} = \set{\vect{a}\in\Rn}{a_i \leq x_i}$. In $\R^2$, this corresponds to the
region (open rectangle) \emph{southwest} of the point $\vect{x} = (x_1,x_2)$.
\subsection{Independence of random variables}
We will primarily be concerned with the concept of independence in the concept of random variables. For the
sake of clarity we will only focus on r.v.~s (i.e maps to real numbers) and random vectors.
\begin{Definition}
    Random variables $X_1,X_2,\dots,X_n$ are independent if the family,
    \[\setX{\sigma{X_1},\sigma{X_2},\dots,\sigma{X_n}},\]
    are independent classes i.e for any events $A_i\in \sigma{X_i}$ the family of events
    \[\set{A_i}{1\leq i \leq n},\]
    are independent, which means for any indices $1\leq i_1 < i_2 \dots < i_k \leq n$,
    \[\probMeasure{A_{i_1}\cap A_{i_2}\dots \cap A_{i_k}} =
	\probMeasure{A_{i_1}}\probMeasure{A_{i_2}}\dots\probMeasure{A_{i_k}}.\] 
\end{Definition}
\begin{Remark}
    Since $\sigma{X_i}$ consists exactly sets of the type $\setX{X_i \in B_i}$ for some Borel set $B_i$,
    $X_1,X_2,\dots,X_n$ are independent iff and only if
    \[\probMeasure{X_1\in B_1,X_2\in B_2\dots, X_n\in B_n} =
	\probMeas_{X_1}(B_1)\dots\probMeas_{X_n}(B_n),\]
    for any Borel sets $B_i$, $1\leq i \leq n$.
    We can write this as,
    \[\probMeasure{\finiteIntersection{\invIm{X_i}{B_i}}{i}{n}} = \finiteProduct{\probMeas_{X_i}(B_i)}{i}{n}.\]
    This observation gives us a useful result,
\end{Remark}
\begin{Proposition}
    Let $X_1,X_2,\dots,X_n$ be r.v.~s and let $\vect{X} = (X_1,X_2,\dots,X_n)$ be the random vector. 
    Then, $X_1,X_2,\dots,X_n$ are independent if and only if,
    \[\probMeas_{\vect{X}} = \probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n},\]
    that is; if the distribution of $\vect{X}$ is the product measure of the distribution of each $X_i$.
\end{Proposition}
\begin{proof}
    Let $X_1,X_2,\dots,X_n$ be independent. Consider a measurable rectangle in $\borelS{\Rn}$,
    \[A = B_1 \times B_2 \times \cdots \times B_n.\]
    By the defintion of product measure,
    \[\left(\probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n}\right)(A) 
	= \finiteProduct{\probMeas_{X_i}(B_i)}{i}{n}.\]
    Now,
    \[\probMeas_X(A) = \probX{\invIm{X}{A}} = \probX{\finiteIntersection{\invImIndx{X}{i}{B_i}}{i}{n}}. \]
    Since, $X_1,X_2,\dots,X_n$ are independent,
    \[\probX{\finiteIntersection{\invImIndx{\vect{X}}{i}{B_i}}{i}{n}} = 
	\finiteProduct{\probX{\invImIndx{X}{i}{B_i}}}{i}{n} 
	= \finiteProduct{\probMeas_{X_i}(B_i)}{i}{n}
	= \left(\probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n}\right)(A).\]
    Thus, $\probMeas_{\vect{X}}$ and $\probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n}$
    agree on the class of measurable rectangles, which is a $\pi$-class and so they agree on the sigma-algebra
    $\borelS{\Rn}$.

    Conversely, assume 
    \[\probMeas_{\vect{X}} = \probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n},\]
    Then,
    \[\probX{\finiteIntersection{\invImIndx{X}{i}{B_i}}{i}{n}} =
	\probX{\invIm{\vect{X}}{B_1\times B_2\times\cdots B_n}} =
	(\fog{\probMeas}{\vect{X}^{-1}})(B_1\times B_2 \times \cdots \times B_n) \]
    By assumption,
    \[(\fog{\probMeas}{\vect{X}^{-1}})(B_1\times B_2 \times \cdots \times B_n) 
	= \left(\probMeas_{X_1}\times\probMeas_{X_2}\times\cdots\times\probMeas{X_n}\right)(B_1\times B_2
	\times \cdots \times B_n) \] 
    But the last term is just
    \[\finiteProduct{\probMeas_{X_i}(B_i)}{i}{n},\]
    by the definition of product measure.
    Hence, we get independence by observing that $\probMeas_{X_i}(B_i) = \probX{\invImIndx{X}{i}{B_i}}$.
\end{proof}
We can extend the definition of independence of finite r.v.~s to the case of an arbitrary collection of
r.v.~s.
\begin{Definition}
    We say that a collection of r.v.~s $\set{X_{\lambda}}{\lambda \in \Lambda}$ are independent if the
    collection of classes $\set{\sigma{X_{\lambda}}}{\lambda \in \Lambda}$ are independent.
\end{Definition}

\section{Expectations and moments}
Let $\probS$ be a probability space and let $X$ be an r.v.~on $\probS$.
\begin{Definition}[name=Expectation]
    The expectation of $X$, denoted by $\eX{X}$, is the integral,
    \[\eX{X} = \lInt{X}{\probMeas}{\Omega},\]
    whenever it exists. We say that the expectation is finite, if $X$ is integrable.
\end{Definition}
\begin{Remark}
    If the expectation of $X$ exists, then for any set $E \in \famF$,
    \[\eX{X\indiFunc{E}} = \lInt{X}{\probMeas}{E}.\]
    We use the notation $\indiFunc{E}$ to denote the characteristic function of the set $E$. The
    characteristic function in probability has a different meaning and so we will be using the notation
    $\indiFunc{E}$ to denote the usual characteristic function of the set. As noted before, we call
    $\indiFunc{E}$, the \emph{indicator} function of the set $E$.
\end{Remark}
All the properties for the integral in a measure space carry over for the expectation of a random variable. We
list them here for completeness.
\begin{Observation}
    We list the properties of expectation. Let $X,Y$ be r.v.~s, let $a,b$ be real numbers and let $E$ be a set
    in $\famF$.
    \begin{properties}[series=expect]
    \item
	(absolute integrability) \[\eX{X\indiFunc{E}} < \infty \iff \eX{\abs{X}\indiFunc{E}} < \infty\]
    \item
	(Linearity) \[\eX{(aX + bY)\indiFunc{E}} = a\eX{X\indiFunc{E}} + b \eX{Y\indiFunc{E}}.\]
    \item
	(Additivity over sets) If $E_n$'s are disjoint and let $E = \countUnion{E_n}{n}$
	\[\eX{X\indiFunc{E}} = \sum\limits_{n}\eX{X\indiFunc{E_n}}.\]
    \item
	(Positivity) If $X$ is non-negative over $E$, then,
	\[\eX{X\indiFunc{E}} \ge 0.\]
    \item
	(Monotonicity) Let $X_1,X_2$ be r.v.~s such that $X_1 \leq X \leq X_2$ a.s.~on $E$, then,
	\[\eX{X_1\indiFunc{E}} \leq \eX{X\indiFunc{E}} \leq \eX{X_2\indiFunc{E}}.\]
    \item
	(Mean Value) If $a \leq X \leq b$ a.s.~on $E$, then
	\[a\probX{E} \leq \eX{X\indiFunc{E}} \leq b\probX{E}.\]
    \item
	(Modulus inequality)
	\[\abs{\eX{X\indiFunc{E}}} \leq \eX{\abs{X}\indiFunc{E}}.\]
    \end{properties}
\end{Observation}
Similarly, for a sequence of r.v.~s we can use the results from the limit theorems to observe,
\begin{Observation}
    Let $\seq{X}{n}$ be a sequence of r.v.~s on $\probS$.
    \begin{properties}[resume*=expect]
    \item
	(MCT) If $X_n \ge 0$ for each $n$ and $\atobUp{X_n}{X}$ a.s.~on $E$, then
	\[\lim\limits_{n\to\infty}\eX{X_n\indiFunc{E}} = \eX{X\indiFunc{E}} =
	    \eX{\lim\limits_{n\to\infty}X_n\indiFunc{E}}.\]
    \item
	(Fatou's Lemma) If $X_n \ge 0$ for each $n$ a.s.~on $E$, then,
	\[\eX{\liminf\limits_{n\to\infty} X_n\indiFunc{E}} \leq \lim\limits_{n\to\infty}\eX{X_n\indiFunc{E}}.\]
    \item
	(Integration term by term) If,
	\[\series{\eX{\abs{X_n}\indiFunc{E}}}{n}{1}{\infty} < \infty,\]
	then,
	$\series{\abs{X_n}}{n}{1}{\infty}$ converges a.s.~on $E$ and,
	\[\eX{\series{X_n}{n}{1}{\infty}\indiFunc{E}} = \series{\eX{X_n\indiFunc{E}}}{n}{1}{\infty}.\]
    \item
	(DCT) If $X_n\to X$ a.s.~on $E$ and for each $n$, $\abs{X_n} \leq Y$, where $Y$ is an integrable
	r.v.~on $\probS$, then
	\[\lim\limits_{n\to\infty}\eX{X_n\indiFunc{E}} = \eX{X\indiFunc{E}} =
	    \eX{\lim\limits_{n\to\infty}X_n\indiFunc{E}}.\]
	In particular the result holds if $Y = M$, where $M > 0$ is a constant.
    \end{properties}
\end{Observation}
The next theorem gives boundes on the expectation of a r.v.~in terms of \emph{tail} probabilities.
\begin{Theorem}
    Let $X$ be a r.v.~on $\probS$. Then,
    \[\series{\probX{\abs{X}\geq n}}{n}{1}{\infty} \leq \eX{\abs{X}} \leq 
	1 + \series{\probX{\abs{X}\geq n}}{n}{1}{\infty}, \]
    so that $\eX{\abs{X}} < \infty$ if and only if the series above converges.
\end{Theorem}
\begin{proof}
\end{proof}


